{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1otwsOo2cwEwpxH1qabt517MH75K2NmzE",
     "timestamp": 1695614167191
    },
    {
     "file_id": "1n9cfGE0sI6sHfOzsAQhZOR8afPIqgCO6",
     "timestamp": 1695269303209
    },
    {
     "file_id": "1I0KA4wCjVa0s9YZsLkAX6JaN-bAdLUlb",
     "timestamp": 1695269238458
    }
   ],
   "machine_shape": "hm",
   "gpuType": "A100",
   "authorship_tag": "ABX9TyOzIRLsiw7Jsa2b3cnklVnB"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformers\n",
    "\n",
    "Â© Data Trainers LLC. GPL v 3.0.\n",
    "\n",
    "Author: Axel Sirota\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Inspired highly on the tutorial [NMT with Transformers](https://www.tensorflow.org/text/tutorials/transformer) which takes the code from the original Transformer model paper originally proposed in [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762) by Vaswani et al. (2017)."
   ],
   "metadata": {
    "id": "gzf37X_XizQQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prep"
   ],
   "metadata": {
    "id": "ovyaAhLpa55P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U nltk 'gensim==4.2.0' 'keras-nlp' 'keras-preprocessing' 'tensorflow-text>=2.11'"
   ],
   "metadata": {
    "id": "C9BTEOu0PerV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435173058,
     "user_tz": 180,
     "elapsed": 5697,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "e253d183-bd0c-4974-91c9-e378c0e0ce98"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
      "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.10/dist-packages (0.6.3)\n",
      "Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
      "Requirement already satisfied: tensorflow-text>=2.11 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (6.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.7)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.11) (0.15.0)\n",
      "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.11) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (67.7.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.15.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (0.0.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.41.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text>=2.11) (3.2.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "wSaLeBcpqiT5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435173059,
     "user_tz": 180,
     "elapsed": 8,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0fpgYwAtNO2T",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435176929,
     "user_tz": 180,
     "elapsed": 3876,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "6e817e4d-9dbd-4bb9-adeb-a553a0cd3ba3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from textblob import TextBlob, Word\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import Model, Input\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "TRACE = False\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "  random.seed(42)\n",
    "  if TRACE:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def set_session_with_gpus_and_cores():\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(config=config)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "set_seeds_and_trace()\n",
    "set_session_with_gpus_and_cores()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Transformer Layers\n",
    "\n",
    "In this demo we will create, from scratch, with the same tools the original Authors had, the Transformer architecture. Why? To understand how it works, why it works, and exactly what is novel!\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The original Transformer diagram</th>\n",
    "  <th colspan=1>A representation of a 4-layer Transformer</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img width=307 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-4layer-compact.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Each of the components in these two diagrams will be explained as you progress through the demo.\n"
   ],
   "metadata": {
    "id": "ekM1n0-JdYPN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What did we have before?"
   ],
   "metadata": {
    "id": "OFbNft2shTPp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before, we used Cross Attention or self attention, remember? And for sequence data we basically used it like this:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>Seq2Seq with attention</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.dropbox.com/s/r6u7ll5nlt96t9f/seq2seq.png?raw=1\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ],
   "metadata": {
    "id": "Q2FoDkeGhWJk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Where we input attention with the hidden state to create another updated hidden state we could input into the next cell. And this worked well on medium sized sentences, but was hard to train and unstable. Now that we know this, the Transformer basicaly tried to get rid of the RNN by using **only** attention"
   ],
   "metadata": {
    "id": "b3huYRrUjCAI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The embedding and positional encoding layer\n",
    "\n",
    "The inputs to both the encoder and decoder use the same embedding and positional encoding logic.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/PositionalEmbedding.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "vwmp1jC0dxVJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## This comes straight from the paper\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ],
   "metadata": {
    "id": "UkI09F6zdXnb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435176930,
     "user_tz": 180,
     "elapsed": 11,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ],
   "metadata": {
    "id": "gLC8RPIkd--M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435176930,
     "user_tz": 180,
     "elapsed": 9,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pos = PositionalEmbedding(5000, 100)"
   ],
   "metadata": {
    "id": "GAnc5AKSeOvn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435176931,
     "user_tz": 180,
     "elapsed": 10,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input = tf.constant(np.random.randint(1,5000, size=(3,26)))\n",
    "response = pos(input)\n",
    "response.shape"
   ],
   "metadata": {
    "id": "zlIZmHLMemkR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177543,
     "user_tz": 180,
     "elapsed": 621,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "ed59da9e-84a1-42fd-e0ab-6010287e4b68"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "response._keras_mask"
   ],
   "metadata": {
    "id": "XnIEkVWqg59O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177544,
     "user_tz": 180,
     "elapsed": 19,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "93fd806b-ea7e-4c42-f6af-1bfc304fc2e1"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 26), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True]])>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add and normalize\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=2>Add and normalize</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Add+Norm.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "yvlTAaqqhTBo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Use `Add` layer instead of + to propagate masks\n",
    "\n",
    "We will create a BaseAttention layer that inherits the Add+Norm and then each subclass of attention will implement the correct one"
   ],
   "metadata": {
    "id": "P-ZTlyygheuT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ],
   "metadata": {
    "id": "OMMyVtc6hLaM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177544,
     "user_tz": 180,
     "elapsed": 12,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self Attention layer\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The global self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/SelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "L5Toc-Uukh15"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    # We need to compare everything with everything, therefore Q, K and V must be the input\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])  # This one comes from the base class\n",
    "    x = self.layernorm(x)  # This one comes from the base class\n",
    "    return x"
   ],
   "metadata": {
    "id": "RP4L1Mn-iFCl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177544,
     "user_tz": 180,
     "elapsed": 11,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test it!"
   ],
   "metadata": {
    "id": "316Iwonjm6JY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "\n",
    "# First we apply the PositionalEmbedding to embed into what the attention layer expects\n",
    "pos = PositionalEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Then we do the self attention, the n_heads is arbitrary\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim)\n",
    "\n",
    "\n",
    "response = gsa(pos(input))\n",
    "response.shape"
   ],
   "metadata": {
    "id": "goX_DO0Sk8UB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177545,
     "user_tz": 180,
     "elapsed": 12,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "0290e15e-002a-401e-cc42-d563c2480a8e"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the shape is the same, since MHA concats all 3 heads and the we add everything"
   ],
   "metadata": {
    "id": "n5lGk8ZMle7K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The cross attention layer\n",
    "\n",
    "This layer connects the encoder and decoder. This layer is the most straight-forward use of attention in the model, it performs the same task as the attention block in the previous demo (and we will copy it).\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The cross attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "J76TA2ZMlrke"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,  # This is the key part!!\n",
    "        value=context,  # This is the key part!!\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "id": "OxZMLVBRlMPz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177545,
     "user_tz": 180,
     "elapsed": 6,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_es = PositionalEmbedding(vocab_size_es, embedding_dim_es)\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim_es)\n",
    "cross = CrossAttention(num_heads=3, key_dim=embedding_dim_en)\n",
    "\n",
    "\n",
    "context = gsa(pos_es(input_es)) # Forget about the feed forwards\n",
    "\n",
    "response = cross(pos_en(input_en), context=context) # Forget about masked attention for now, assume it is the identity\n",
    "\n",
    "response.shape"
   ],
   "metadata": {
    "id": "R9v9MPbvmVJw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177906,
     "user_tz": 180,
     "elapsed": 367,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "696290e9-7a93-4d70-de24-1e12a53c612e"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the shape is (batch_size, words in sentence in output, embedding_dim) , regardless the input sentence had more words or other embedding dim. We are doing a good move forward!"
   ],
   "metadata": {
    "id": "e5bXoAwvoD8T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The causal self attention layer (Masked Multi Headed Attention)\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ],
   "metadata": {
    "id": "PuNqXT82oaRo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only big difference in the masked multi headedd attention is that we cannot attend to words in the future, so we will use a mask such that the `Nth` word can only see the first `N-1` words and not all the sentence."
   ],
   "metadata": {
    "id": "_-jDIHkJowAP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)  # This is the key!\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ],
   "metadata": {
    "id": "z6N9U3qvn9Ui",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177906,
     "user_tz": 180,
     "elapsed": 18,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=330 src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "PgCBG1b-osuv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice in the diagram above how the query can onlly attend the values for the past"
   ],
   "metadata": {
    "id": "AdE_KY2TpEPC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "csa = CausalSelfAttention(num_heads =3, key_dim=embedding_dim_en)\n",
    "\n",
    "response = csa(pos_es(input_en))\n",
    "\n",
    "response.shape"
   ],
   "metadata": {
    "id": "RaHIa0k4oqD1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177906,
     "user_tz": 180,
     "elapsed": 17,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "be378e2e-2b3b-452f-c901-bd58871feed6"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The feed forward network\n",
    "\n",
    "The transformer also includes this point-wise feed-forward network in both the encoder and decoder:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The feed forward network</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/FeedForward.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "c8_jJCg8pE6b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x\n"
   ],
   "metadata": {
    "id": "Wu5xFoRjpBty",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177907,
     "user_tz": 180,
     "elapsed": 11,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The encoder layer\n",
    "\n",
    "The encoder contains a stack of `N` encoder layers. Where each `EncoderLayer` contains a `GlobalSelfAttention` and `FeedForward` layer:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The encoder layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/EncoderLayer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "1Pm7uGPMpqwu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ],
   "metadata": {
    "id": "3SJl4aJ_pSR0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177907,
     "user_tz": 180,
     "elapsed": 11,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "pos = PositionalEmbedding(vocab_size, embedding_dim)\n",
    "sample_encoder_layer = EncoderLayer(d_model=embedding_dim, num_heads=3, dff=1012)\n",
    "response = sample_encoder_layer(pos(input))\n",
    "response.shape"
   ],
   "metadata": {
    "id": "4NUNWld5uOBo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435177907,
     "user_tz": 180,
     "elapsed": 10,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "bcc66b27-13ae-4653-d2ee-29fc3ae1e12d"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The encoder\n",
    "\n",
    "Notice we need to be able to repeat the past EncoderLayer Nx times, so we need another Layer that is able to do exactly that\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The encoder</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "-MzC1z-vuuxF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ],
   "metadata": {
    "id": "0TlZP_vVulm0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435178164,
     "user_tz": 180,
     "elapsed": 263,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "sample_encoder = Encoder(num_layers=4,\n",
    "                         d_model=embedding_dim,\n",
    "                         num_heads=3,\n",
    "                         dff=512,\n",
    "                         vocab_size=vocab_size)\n",
    "response = sample_encoder(input)\n",
    "response.shape"
   ],
   "metadata": {
    "id": "Yf9wGOSMwaEt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435178749,
     "user_tz": 180,
     "elapsed": 587,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "19dded2a-508d-4881-b2f9-c8cbea475188"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got our Encoder!! Yahoo!!"
   ],
   "metadata": {
    "id": "uUU9CG_MwtJC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The decoder layer\n",
    "\n",
    "Same as before we need a Decoder layer that uses the Attention layers and then another layer to permit having Nx layers of decoding\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The decoder layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/DecoderLayer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "UR4MuroWw4p-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ],
   "metadata": {
    "id": "_v5voBr2wywC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435178750,
     "user_tz": 180,
     "elapsed": 8,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "\n",
    "encoder =  Encoder(num_layers=2, d_model=embedding_dim_es, num_heads=3, dff=512, vocab_size=vocab_size_es)\n",
    "\n",
    "context = encoder(input_es)\n",
    "\n",
    "decoder_layer = DecoderLayer(d_model=embedding_dim_en, num_heads=3, dff=218, dropout_rate=0.2)\n",
    "\n",
    "response = decoder_layer(pos_en(input_en), context=context)\n",
    "\n",
    "response.shape"
   ],
   "metadata": {
    "id": "aP3yjQeuy2n4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435179147,
     "user_tz": 180,
     "elapsed": 405,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "aef417a6-57bc-4f7d-f645-e5936f90f7c7"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Decoder\n",
    "\n",
    "Similar to the `Encoder`, the `Decoder` consists of a `PositionalEmbedding`, and a stack of `DecoderLayer`s:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Decoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "pog5S-gQz9nF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ],
   "metadata": {
    "id": "dEZ2-NRbz1jz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435179149,
     "user_tz": 180,
     "elapsed": 4,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "encoder =  Encoder(num_layers=2, d_model=embedding_dim_es, num_heads=3, dff=512, vocab_size=vocab_size_es)\n",
    "\n",
    "context = encoder(input_es)\n",
    "\n",
    "decoder = Decoder(num_layers=3, d_model=embedding_dim_en, num_heads=5, dff=124, vocab_size=vocab_size_en)\n",
    "\n",
    "response = decoder(input_en, context=context)\n",
    "\n",
    "response.shape"
   ],
   "metadata": {
    "id": "Mp4zkTw22-23",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435179848,
     "user_tz": 180,
     "elapsed": 703,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "96c0cb19-acce-4e8f-fbb6-2d23f17986f0"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Transformer Model\n",
    "\n",
    "You now have `Encoder` and `Decoder`. To complete the `Transformer` model, you need to put them together and add a final linear (`Dense`) layer which converts the resulting vector at each location into output token probabilities.\n",
    "\n",
    "The output of the decoder is the input to this final linear layer.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The transformer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ],
   "metadata": {
    "id": "3r2JLfz04Hsc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ],
   "metadata": {
    "id": "VrXSLwrF36u_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435179849,
     "user_tz": 180,
     "elapsed": 5,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_dim = 100\n",
    "vocab_size_es = 5000\n",
    "vocab_size_en = 6000\n",
    "\n",
    "num_layers = 4\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=embedding_dim,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=vocab_size_es,\n",
    "    target_vocab_size=vocab_size_en,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "response = transformer((input_es, input_en))\n",
    "response.shape"
   ],
   "metadata": {
    "id": "7CIxbfVx9IBc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435180688,
     "user_tz": 180,
     "elapsed": 843,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "6df8a97c-d551-473f-f0f6-1e425aef2ca9"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 6000])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "transformer.summary()\n"
   ],
   "metadata": {
    "id": "Gy5B7d_E-NDE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435180688,
     "user_tz": 180,
     "elapsed": 17,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "04b22156-2b0c-4aa7-c49f-539324a65253"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_3 (Encoder)         multiple                  2203648   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  3594448   \n",
      "                                                                 \n",
      " dense_42 (Dense)            multiple                  606000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6404096 (24.43 MB)\n",
      "Trainable params: 6404096 (24.43 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "VqnWfvyM7XDJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435180688,
     "user_tz": 180,
     "elapsed": 9,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download and prepare the dataset\n",
    "\n",
    "The steps you need to take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word â id and id â word).\n",
    "4. Pad each sentence to a maximum length.\n"
   ],
   "metadata": {
    "id": "4_gfORYlopD0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile get_data.sh\n",
    "if [ ! -f spa.txt ]; then\n",
    "  wget -O spa.txt https://www.dropbox.com/s/ke42pnpydmy6oa6/spa.txt?dl=0\n",
    "fi"
   ],
   "metadata": {
    "id": "yFxoDROBpG5G",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435180689,
     "user_tz": 180,
     "elapsed": 9,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "865d0582-c2d1-48b2-f1ee-af3de9b7190c"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting get_data.sh\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!bash get_data.sh"
   ],
   "metadata": {
    "id": "O2SKVt9TqEIw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435180689,
     "user_tz": 180,
     "elapsed": 6,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! head spa.txt"
   ],
   "metadata": {
    "id": "5adiYIJJqFlK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435181149,
     "user_tz": 180,
     "elapsed": 465,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "24ba6ffd-e766-48d8-d0c8-492eed3d1f4e"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Go.\tVe.\n",
      "Go.\tVete.\n",
      "Go.\tVaya.\n",
      "Go.\tVÃ¡yase.\n",
      "Hi.\tHola.\n",
      "Run!\tÂ¡Corre!\n",
      "Run.\tCorred.\n",
      "Who?\tÂ¿QuiÃ©n?\n",
      "Fire!\tÂ¡Fuego!\n",
      "Fire!\tÂ¡Incendio!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(path):\n",
    "  text = path.read_text(encoding='utf-8')\n",
    "\n",
    "  lines = text.splitlines()\n",
    "  pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "  context = np.array([context for target, context in pairs])\n",
    "  target = np.array([target for target, context in pairs])\n",
    "\n",
    "  return target, context"
   ],
   "metadata": {
    "id": "NEvGjgBCqOqs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435181150,
     "user_tz": 180,
     "elapsed": 8,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pathlib\n",
    "target_raw, context_raw = load_data(pathlib.Path('./spa.txt'))\n",
    "print(context_raw[-1])"
   ],
   "metadata": {
    "id": "H6_Mg1wtqWiQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435181577,
     "user_tz": 180,
     "elapsed": 434,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "5781b8c3-3649-4675-fd77-e8e5ead619af"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un mÃºsico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(target_raw[-1])"
   ],
   "metadata": {
    "id": "9W_00eXhqair",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435181577,
     "user_tz": 180,
     "elapsed": 6,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "cc73ff70-a8fb-4f65-f556-6576d5f922d9"
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ],
   "metadata": {
    "id": "FDwRq7K7q3md",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435181852,
     "user_tz": 180,
     "elapsed": 277,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for example_context_strings, example_target_strings in train_raw.take(1):\n",
    "  print(example_context_strings[:5])\n",
    "  print()\n",
    "  print(example_target_strings[:5])\n",
    "  break"
   ],
   "metadata": {
    "id": "dXznSCd9uoDy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 328,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "f9504891-f258-49b3-84f9-364b11a63e4b"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[b'Estoy muy orgulloso de esto.'\n",
      " b'\\xc2\\xbfSab\\xc3\\xadas que Tom y Mary eran primos?'\n",
      " b'Tom quit\\xc3\\xb3 la tapa de la caja.'\n",
      " b'\\xc2\\xbfPor qu\\xc3\\xa9 no est\\xc3\\xa1s comiendo?' b'La he visto antes.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b\"I'm really proud of this.\" b'Did you know Tom and Mary were cousins?'\n",
      " b'Tom removed the lid from the box.' b\"Why aren't you eating?\"\n",
      " b'I have seen her before.'], shape=(5,), dtype=string)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kYCMheWVmTwD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 12,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text processing"
   ],
   "metadata": {
    "id": "GMiMKp7zyCPb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. Mainly using a `layers.TextVectorization` layer."
   ],
   "metadata": {
    "id": "kAW-e9tjyBUE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "example_text = tf.constant('Â¿TodavÃ­a estÃ¡ en casa?')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ],
   "metadata": {
    "id": "NGMCXqX0uqVN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 11,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "808e9de4-8f33-436e-a98f-8b85b639a4d4"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "  # Split accented characters.\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "  text = tf.strings.lower(text)\n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,Â¿]', '')\n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[.?!,Â¿]', r' \\0 ')\n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "  return text"
   ],
   "metadata": {
    "id": "ZJ3IrLGayGb_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 8,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ],
   "metadata": {
    "id": "27J5Iii0yPwL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 8,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "b1c57249-7292-4e96-e381-c7ec591dde8f"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Â¿TodavÃ­a estÃ¡ en casa?\n",
      "[START] Â¿ todavia esta en casa ? [END]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Vectorization\n"
   ],
   "metadata": {
    "id": "K_fqO7pRyrF0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here comes the key part, using the layer TextVectorization we provide how to process text and how to construct the vocabulary, which we will later refer back"
   ],
   "metadata": {
    "id": "HGL6UpJp2XVK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=vocab_size_es,\n",
    "    ragged=True)"
   ],
   "metadata": {
    "id": "X6EERfaPyRo8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435182178,
     "user_tz": 180,
     "elapsed": 4,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "context_text_processor.get_vocabulary()[:10]"
   ],
   "metadata": {
    "id": "E5pNEEkGyuQv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435183305,
     "user_tz": 180,
     "elapsed": 1129,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "f41403ae-b1c7-491a-ac37-2e026c0de201"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=vocab_size_en,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "target_text_processor.get_vocabulary()[:10]"
   ],
   "metadata": {
    "id": "4DOY9054yyct",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435184125,
     "user_tz": 180,
     "elapsed": 823,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "f7cbf0ff-315a-458b-ec13-542d6a15106c"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "notice we passed to ids, not padded yet"
   ],
   "metadata": {
    "id": "XoJUN_bm0-vW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "example_tokens = context_text_processor(example_context_strings)\n",
    "example_tokens[:3, :]"
   ],
   "metadata": {
    "id": "HimOaXcQzGf2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435184125,
     "user_tz": 180,
     "elapsed": 12,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "9b49e7f9-251a-4eae-e9ff-0313b54563e1"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 41, 42, 1040, 6, 57, 4, 3],\n",
       " [2, 13, 1863, 5, 10, 33, 32, 612, 2317, 12, 3],\n",
       " [2, 10, 1141, 11, 3357, 6, 11, 450, 4, 3]]>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0FchVAH6nRmz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435184126,
     "user_tz": 180,
     "elapsed": 6,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def process_text(context, target):\n",
    "  context = context_text_processor(context).to_tensor()\n",
    "  target = target_text_processor(target)\n",
    "  targ_in = target[:,:-1].to_tensor()\n",
    "  targ_out = target[:,1:].to_tensor()\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "id": "pzfHsUTz1EeS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435184520,
     "user_tz": 180,
     "elapsed": 399,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "Hk68lpA5npoL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  print(ex_context_tok[0, :10].numpy())\n",
    "  print()\n",
    "  print(ex_tar_in[0, :10].numpy())\n",
    "  print(ex_tar_out[0, :10].numpy())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0ZBZaIjrAug",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435184520,
     "user_tz": 180,
     "elapsed": 6,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "73e1717e-572b-4409-fd11-e192e9b4a319"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  2  13  21   5 196  91  12   3   0   0]\n",
      "\n",
      "[ 2 78 20 16 98 11  0  0  0  0]\n",
      "[78 20 16 98 11  3  0  0  0  0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "logits = transformer((ex_context_tok, ex_tar_in))\n",
    "\n",
    "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
    "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "te1qN-cLnlPP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435187717,
     "user_tz": 180,
     "elapsed": 3201,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    },
    "outputId": "3a52ad48-8d43-4460-aafe-22a4380e02bf"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Context tokens, shape: (batch, s, units) (256, 32)\n",
      "Target tokens, shape: (batch, t) (256, 30)\n",
      "logits, shape: (batch, t, target_vocabulary_size) (256, 30, 6000)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dwSAC7bgn0Ca",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435187718,
     "user_tz": 180,
     "elapsed": 15,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ],
   "metadata": {
    "id": "EQpVGnsFz1UL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435187718,
     "user_tz": 180,
     "elapsed": 13,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ],
   "metadata": {
    "id": "QR4M7-6jCPOC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435187719,
     "user_tz": 180,
     "elapsed": 13,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer.compile(optimizer='adam',\n",
    "              loss=masked_loss,\n",
    "              metrics=[masked_acc, masked_loss])"
   ],
   "metadata": {
    "id": "L46lhkXcCRVf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700435187719,
     "user_tz": 180,
     "elapsed": 12,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     }
    }
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = transformer.fit(\n",
    "    train_ds,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=50,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ],
   "metadata": {
    "id": "Y0whEYLfCTXL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "843e42eb-04fa-49ff-e7b8-9f02a17d6596"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "50/50 [==============================] - 166s 3s/step - loss: 6.4545 - masked_acc: 0.1924 - masked_loss: 6.4519 - val_loss: 5.2232 - val_masked_acc: 0.2492 - val_masked_loss: 5.2233\n",
      "Epoch 2/25\n",
      "17/50 [=========>....................] - ETA: 1:24 - loss: 5.0945 - masked_acc: 0.2494 - masked_loss: 5.0949"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('CE/token')\n",
    "plt.legend()"
   ],
   "metadata": {
    "id": "p-6tYeLrCWfl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['masked_acc'], label='accuracy')\n",
    "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('CE/token')\n",
    "plt.legend()"
   ],
   "metadata": {
    "id": "ODcFQZlNCcrN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "context_text_processor('Hola')"
   ],
   "metadata": {
    "id": "5LRJdwQ7sQ-3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translate"
   ],
   "metadata": {
    "id": "ARqmE2hkC4Y5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, context_text_processor, target_text_processor, transformer, max_tokens=50):\n",
    "    self.context_text_processor = context_text_processor\n",
    "    self.target_text_processor = target_text_processor\n",
    "    self.index2word = { i : word for i, word in enumerate(target_text_processor.get_vocabulary())}\n",
    "    self.transformer = transformer\n",
    "    self.max_tokens = max_tokens\n",
    "\n",
    "  def __call__(self, sentence):\n",
    "\n",
    "    sentence = context_text_processor(sentence)[tf.newaxis]\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # Spanish `[START]` token.\n",
    "    start = encoder_input[0][0][tf.newaxis]\n",
    "    end = encoder_input[0][-1][tf.newaxis]\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(self.max_tokens):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer((encoder_input, output), training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    translated_text = ' '.join([ index2word.get(token) for token in tokens[0].numpy()])\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    # self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    # attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return output, translated_text"
   ],
   "metadata": {
    "id": "duEBiVvgp9vY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "30qLcmX0trCj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NjbvpHUTEia"
   },
   "outputs": [],
   "source": [
    "translator = Translator(transformer=transformer, context_text_processor=context_text_processor, target_text_processor=target_text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfHSRdejTFsC"
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, translated_text, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens.numpy()}')\n",
    "  print(f'{\"Prediction\":15s}: {translated_text}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpLsbZieybKP"
   },
   "source": [
    "Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y61QABh8ybKQ"
   },
   "outputs": [],
   "source": [
    "sentence = 'Si me quieren encontrar, busquen en el cielo del oeste'\n",
    "ground_truth = 'If you want to find me, look for the western sky'\n",
    "\n",
    "tokens, translated_text = translator(\n",
    "    sentence)\n",
    "print_translation(sentence, tokens, translated_text, ground_truth)"
   ]
  }
 ]
}